{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep_learning_QSM_tutorial_OHBM.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/martinhavlicek/OHBM-hackathons-on-using-DNNs/blob/master/Deep_learning_QSM_tutorial_OHBM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22AQPIN4-e7Q",
        "colab_type": "text"
      },
      "source": [
        "#Intro\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTyYQSFM-jCV",
        "colab_type": "text"
      },
      "source": [
        "Disclaimer: This code is not the DeepQSM source code used in the publications and was newly written for the OHBM educational course.\n",
        "\n",
        "Intro to Jupyter/Colab notebooks & Keras from last year's course:\n",
        "https://colab.research.google.com/github/akeshavan/IntroDL/blob/master/IntroToKeras.ipynb\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ck6k3uUE15d0",
        "colab_type": "text"
      },
      "source": [
        "# QSM data from the 2018 reconstruction challenge\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLdtGn4R39FU",
        "colab_type": "text"
      },
      "source": [
        "## Download data to google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgWQKVCa16RG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from google.colab import drive\n",
        "# import os\n",
        "\n",
        "# drive.mount('/content/gdrive')\n",
        "# !mkdir -p /content/gdrive/My\\ Drive/dlqsm\n",
        "# os.chdir(\"/content/gdrive/My Drive/dlqsm\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQMqbSiV3FaK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# uncomment to download the data again\n",
        "!wget -nc http://www.neuroimaging.at/media/qsm/20170327_qsm2016_recon_challenge.zip\n",
        "!unzip -uo 20170327_qsm2016_recon_challenge.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nthOBhTZ8otM",
        "colab_type": "text"
      },
      "source": [
        "## View QSM data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfH2Rhl4FUN8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def view_slices_3d(image_3d, slice_nbr, vmin, vmax, title=''):\n",
        "#   print('Matrix size: {}'.format(image_3d.shape))\n",
        "  fig = plt.figure(figsize=(6, 3))\n",
        "  plt.suptitle(title, fontsize=10)\n",
        "\n",
        "  plt.subplot(131)\n",
        "  plt.imshow(np.take(image_3d, slice_nbr, 2), vmin=vmin, vmax=vmax, cmap='gray')\n",
        "  plt.title('Axial');\n",
        "\n",
        "  plt.subplot(132)\n",
        "  image_rot = ndimage.rotate(np.take(image_3d, slice_nbr, 1),90)\n",
        "  plt.imshow(image_rot, vmin=vmin, vmax=vmax, cmap='gray')\n",
        "  plt.title('Coronal');\n",
        "\n",
        "  plt.subplot(133)\n",
        "  image_rot = ndimage.rotate(np.take(image_3d, slice_nbr, 0),90)\n",
        "  plt.imshow(image_rot, vmin=vmin, vmax=vmax, cmap='gray')\n",
        "  plt.title('Sagittal');\n",
        "  cbar=plt.colorbar()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48ItM40hEccm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nibabel as nib\n",
        "import numpy as np\n",
        "from matplotlib import transforms\n",
        "from scipy import ndimage\n",
        "\n",
        "# load data\n",
        "brain_fw_full = nib.load('20170327_qsm2016_recon_challenge/data/phs_tissue.nii.gz').get_data()\n",
        "brain_gt_full = nib.load('20170327_qsm2016_recon_challenge/data/chi_33.nii.gz').get_data()\n",
        "\n",
        "view_slices_3d(brain_fw_full, slice_nbr=100, vmin=-0.05, vmax=0.05, title='Tissue Phase')\n",
        "view_slices_3d(brain_gt_full, slice_nbr=100, vmin=-0.05, vmax=0.05, title='\"Gold-Standard\" QSM')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRYxKuOyTMaT",
        "colab_type": "text"
      },
      "source": [
        "# Simulate susceptibility sources and tissue phase\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSazY-TzPGod",
        "colab_type": "text"
      },
      "source": [
        "## Simulate susceptibility distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fVQDQAuEgJI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def simulate_susceptibility_sources(simulation_dim = 160, \n",
        "                                    rectangles_total = 100,\n",
        "                                    spheres_total = 80,\n",
        "                                    sus_std = 1,     # standard deviation of susceptibility values\n",
        "                                    shape_size_min_factor = 0.01,\n",
        "                                    shape_size_max_factor = 0.5):\n",
        "  \n",
        "  temp_sources = np.zeros((simulation_dim, simulation_dim, simulation_dim))\n",
        "\n",
        "\n",
        "  for shapes in range(rectangles_total):\n",
        "      shrink_factor = 1/((shapes/rectangles_total+1))\n",
        "      shape_size_min = np.floor(simulation_dim * shrink_factor * shape_size_min_factor)\n",
        "      shape_size_max = np.floor(simulation_dim * shrink_factor * shape_size_max_factor)\n",
        "      \n",
        "#       print(shape_size_min)\n",
        "#       print(shape_size_max)\n",
        "#       print('---------------')\n",
        "\n",
        "      susceptibility_value = np.random.normal(loc=0.0, scale=sus_std)\n",
        "      random_sizex = np.random.randint(low=shape_size_min, high=shape_size_max)\n",
        "      random_sizey = np.random.randint(low=shape_size_min, high=shape_size_max)\n",
        "      random_sizez = np.random.randint(low=shape_size_min, high=shape_size_max)\n",
        "      x_pos = np.random.randint(simulation_dim)\n",
        "      y_pos = np.random.randint(simulation_dim)\n",
        "      z_pos = np.random.randint(simulation_dim)\n",
        "\n",
        "      x_pos_max = x_pos + random_sizex\n",
        "      if x_pos_max >= simulation_dim:\n",
        "          x_pos_max = simulation_dim\n",
        "\n",
        "      y_pos_max = y_pos + random_sizey\n",
        "      if y_pos_max >= simulation_dim:\n",
        "          y_pos_max = simulation_dim\n",
        "\n",
        "      z_pos_max = z_pos + random_sizez\n",
        "      if z_pos_max >= simulation_dim:\n",
        "          z_pos_max = simulation_dim\n",
        "\n",
        "      temp_sources[x_pos:x_pos_max, y_pos:y_pos_max, z_pos:z_pos_max] = susceptibility_value\n",
        "    \n",
        "  return temp_sources"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8ttpuxCPXD9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sim_gt_full = simulate_susceptibility_sources(simulation_dim = 320, rectangles_total = 800, spheres_total = 80,)\n",
        "view_slices_3d(sim_gt_full, slice_nbr=100, vmin=-1, vmax=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Puqc3bi3bBjj",
        "colab_type": "text"
      },
      "source": [
        "## Convolve Susceptibility Distribution with Dipole Kernel to yield Tissue Phase"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eB5DSBpMQCRj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_3d_dipole_kernel(data_shape, voxel_size, b_vec):\n",
        "    fov = np.array(data_shape) * np.array(voxel_size)\n",
        "\n",
        "    ry, rx, rz = np.meshgrid(np.arange(-data_shape[1] // 2, data_shape[1] // 2),\n",
        "                             np.arange(-data_shape[0] // 2, data_shape[0] // 2),\n",
        "                             np.arange(-data_shape[2] // 2, data_shape[2] // 2))\n",
        "\n",
        "    rx, ry, rz = rx / fov[0], ry / fov[1], rz / fov[2]\n",
        "\n",
        "    sq_dist = rx ** 2 + ry ** 2 + rz ** 2\n",
        "    sq_dist[sq_dist == 0] = 1e-6\n",
        "    d2 = ((b_vec[0] * rx + b_vec[1] * ry + b_vec[2] * rz) ** 2) / sq_dist\n",
        "    kernel = (1 / 3 - d2)\n",
        "\n",
        "    return kernel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUbkwO2FZyOb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dipole_kernel = generate_3d_dipole_kernel(sim_gt_full.shape, voxel_size=1, b_vec=[0, 0, 1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXxNXRt7RPZC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "view_slices_3d(dipole_kernel, slice_nbr=100, vmin=-0.5, vmax=0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gK12OI15RFFE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def forward_convolution_padding(chi_sample, padding=20):\n",
        "    #pad sample to avoid wrap-around at the edges\n",
        "    padded_sample = np.zeros((chi_sample.shape[0]+2*padding, chi_sample.shape[1]+2*padding, chi_sample.shape[2]+2*padding))\n",
        "    padded_sample[padding:chi_sample.shape[0]+padding, padding:chi_sample.shape[1]+padding, padding:chi_sample.shape[2]+padding] = chi_sample\n",
        "    scaling = np.sqrt(padded_sample.size)\n",
        "    chi_fft = np.fft.fftshift(np.fft.fftn(np.fft.fftshift(padded_sample))) / scaling\n",
        "    \n",
        "    dipole_kernel = generate_3d_dipole_kernel(padded_sample.shape, voxel_size=1, b_vec=[0, 0, 1])\n",
        "    \n",
        "    chi_fft_t_kernel = chi_fft * dipole_kernel\n",
        "   \n",
        "    tissue_phase_unscaled = np.fft.fftshift(np.fft.ifftn(np.fft.fftshift(chi_fft_t_kernel)))\n",
        "    tissue_phase = np.real(tissue_phase_unscaled * scaling)\n",
        "\n",
        "    tissue_phase_cropped = tissue_phase[padding:chi_sample.shape[0]+padding, padding:chi_sample.shape[1]+padding, padding:chi_sample.shape[2]+padding]\n",
        "    \n",
        "    return tissue_phase_cropped\n",
        "  \n",
        "def forward_convolution(chi_sample):\n",
        "    scaling = np.sqrt(chi_sample.size)\n",
        "    chi_fft = np.fft.fftshift(np.fft.fftn(np.fft.fftshift(chi_sample))) / scaling\n",
        "    \n",
        "    chi_fft_t_kernel = chi_fft * generate_3d_dipole_kernel(chi_sample.shape, voxel_size=1, b_vec=[0, 0, 1])\n",
        "   \n",
        "    tissue_phase = np.fft.fftshift(np.fft.ifftn(np.fft.fftshift(chi_fft_t_kernel)))\n",
        "    tissue_phase = np.real(tissue_phase * scaling)\n",
        "\n",
        "    return tissue_phase\n",
        "  \n",
        "sim_fw_full = forward_convolution(sim_gt_full)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kn6ui9R8ar8I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "view_slices_3d(sim_fw_full, slice_nbr=100, vmin=-1, vmax=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Oxzf5kbR5q1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "view_slices_3d(sim_gt_full, slice_nbr=100, vmin=-1, vmax=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqVNG7YWED28",
        "colab_type": "text"
      },
      "source": [
        "#Train a model to invert the dipole convolution using Keras & Tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLlDKZmgS9Fk",
        "colab_type": "text"
      },
      "source": [
        "## Prepare patches for training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTzTFzsxoQQg",
        "colab_type": "text"
      },
      "source": [
        "Due to memory limits on the GPUs and to get more training examples we will cut smaller patches from our simulated data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99lyPz7XpLD0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cut_patch(dim, patch_idx, gt_full, fw_full):\n",
        "    x_max, y_max, z_max = gt_full.shape\n",
        "\n",
        "    randomX = np.random.randint(0, x_max - training_dim)\n",
        "    randomY = np.random.randint(0, y_max - training_dim)\n",
        "    randomZ = np.random.randint(0, z_max - training_dim)\n",
        "\n",
        "    gt_patch = gt_full[randomX:randomX + training_dim, randomY:randomY + training_dim, randomZ:randomZ + training_dim]\n",
        "    fw_patch = fw_full[randomX:randomX + training_dim, randomY:randomY + training_dim, randomZ:randomZ + training_dim]\n",
        "\n",
        "    return gt_patch, fw_patch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e55XbNq5TEUR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "patches_total = 500\n",
        "training_dim = 64\n",
        "\n",
        "# Cut patches from our simulations for training\n",
        "sim_gt_patches = np.zeros((patches_total, training_dim, training_dim, training_dim))\n",
        "sim_fw_patches = np.zeros((patches_total, training_dim, training_dim, training_dim))\n",
        "\n",
        "for patch_idx in range(patches_total):\n",
        "  sim_gt_patches[patch_idx, :, :, :], sim_fw_patches[patch_idx, :, :, :] = cut_patch(training_dim, patch_idx, sim_gt_full, sim_fw_full)\n",
        "\n",
        "# Cut test data patches from a real brain\n",
        "# brain_gt_patches = np.zeros((patches_total, training_dim, training_dim, training_dim))\n",
        "# brain_fw_patches = np.zeros((patches_total, training_dim, training_dim, training_dim))\n",
        "# for patch_idx in range(patches_total):\n",
        "#   brain_gt_patches[patch_idx, :, :, :], brain_fw_patches[patch_idx, :, :, :] = cut_patch(training_dim, patch_idx, brain_gt_full, brain_fw_full)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZDizEXkrm5w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "patch_idx = 44\n",
        "view_slices_3d(sim_fw_patches[patch_idx, :, :, :], slice_nbr=16, vmin=-1, vmax=1, title='Tissue Phase')\n",
        "view_slices_3d(sim_gt_patches[patch_idx, :, :, :], slice_nbr=16, vmin=-1, vmax=1, title='Susceptibility')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5nrh3qqsZOH",
        "colab_type": "text"
      },
      "source": [
        "## Build a model\n",
        "based on \n",
        "* https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/r2/tutorials/generative/pix2pix.ipynb#scrollTo=tqqvWxlw8b4l\n",
        "\n",
        "\n",
        "* https://colab.research.google.com/github/GoogleCloudPlatform/training-data-analyst/blob/master/courses/fast-and-lean-data-science/07_Keras_Flowers_TPU_squeezenet.ipynb#scrollTo=MPkvHdAYNt9J"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smro6GDnAWRg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q tensorflow-gpu==2.0.0-alpha0\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_uOBae0tqrLZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "OUTPUT_CHANNELS = 1\n",
        "def downsample(filters, kernel_size, apply_batchnorm=True):\n",
        "  initializer = tf.random_normal_initializer(0., 0.02)\n",
        "\n",
        "  result = tf.keras.Sequential()\n",
        "  result.add(\n",
        "      tf.keras.layers.Conv3D(filters, kernel_size, strides=2, padding='same',\n",
        "                             kernel_initializer=initializer, use_bias=False))\n",
        "\n",
        "  if apply_batchnorm:\n",
        "    result.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "  result.add(tf.keras.layers.LeakyReLU())\n",
        "\n",
        "  return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VIyqtINrGSQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# bringing things in the right shape for the network (first dimension is batch, then xyz, last dimension is channel)\n",
        "inp = sim_fw_patches[ 0, :, :, :]\n",
        "print(inp.shape)\n",
        "inp = tf.expand_dims(inp, 0)\n",
        "print(inp.shape)\n",
        "inp = tf.expand_dims(inp, 4)\n",
        "print(inp.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvI2Iky7_txk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# testing downsample part\n",
        "down_model = downsample(filters=8, kernel_size=4)\n",
        "down_result = down_model(inp)\n",
        "print (down_result.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nb-Yw-U7r17Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def upsample(filters, kernel_size, apply_dropout=False, apply_batchnorm=True):\n",
        "  initializer = tf.random_normal_initializer(0., 0.02)\n",
        "\n",
        "  result = tf.keras.Sequential()\n",
        "  result.add(\n",
        "    tf.keras.layers.Conv3DTranspose(filters, kernel_size, strides=2,\n",
        "                                    padding='same',\n",
        "                                    kernel_initializer=initializer,\n",
        "                                    use_bias=False))\n",
        "\n",
        "  if apply_batchnorm:\n",
        "      result.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "  if apply_dropout:\n",
        "      result.add(tf.keras.layers.Dropout(0.5))\n",
        "\n",
        "  result.add(tf.keras.layers.ReLU())\n",
        "\n",
        "  return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjGEO0tFr2uc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Testing upsample part\n",
        "up_model = upsample(filters=8, kernel_size=4)\n",
        "up_result = up_model(down_result)\n",
        "print (up_result.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7h9TugdeWLDG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Parameters for all Models\n",
        "import pickle\n",
        "\n",
        "\n",
        "epochs_train = 500\n",
        "save_period = 20\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DU6fsUZJN-hv",
        "colab_type": "text"
      },
      "source": [
        "# Train Model 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-VKM3_HaPF0",
        "colab_type": "text"
      },
      "source": [
        "## Prepare"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSUWrgGAsJnQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def architecture1(filter_base=32, kernel_size=3):\n",
        "  down_stack = [\n",
        "    downsample(filter_base, kernel_size, apply_batchnorm=False), # (bs, 32xxx 64 if filter base = 64)\n",
        "    downsample(filter_base*2, kernel_size), # (bs, 16xxx, 128)\n",
        "    downsample(filter_base*3, kernel_size), # (bs, 8xxx, 256)\n",
        "    downsample(filter_base*4, kernel_size), # (bs, 4xxx, 512)\n",
        "    downsample(filter_base*5, kernel_size), # (bs, 2xxx, 512)\n",
        "  ]\n",
        "\n",
        "  up_stack = [\n",
        "    upsample(filter_base*5, kernel_size, apply_dropout=True), # (bs, 4xxx 1024)\n",
        "    upsample(filter_base*4, kernel_size, apply_dropout=True), # (bs, 8xxxx 512)\n",
        "    upsample(filter_base*3, kernel_size), # (bs, 16xxx 256)\n",
        "    upsample(filter_base*2, kernel_size), # (bs, 32xxx 128)\n",
        "  ]\n",
        "\n",
        "  initializer = tf.random_normal_initializer(0., 0.02)\n",
        "  last = tf.keras.layers.Conv3DTranspose(OUTPUT_CHANNELS, kernel_size,\n",
        "                                         strides=2,\n",
        "                                         padding='same',\n",
        "                                         kernel_initializer=initializer,\n",
        "                                         activation='tanh') # (bs, 256, 256, 3)\n",
        "\n",
        "  concat = tf.keras.layers.Concatenate()\n",
        "\n",
        "  inputs = tf.keras.layers.Input(shape=[None,None,None,1])\n",
        "  x = inputs\n",
        "\n",
        "  # Downsampling through the model\n",
        "  skips = []\n",
        "  for down in down_stack:\n",
        "    x = down(x)\n",
        "    skips.append(x)\n",
        "\n",
        "  skips = reversed(skips[:-1])\n",
        "\n",
        "  # Upsampling and establishing the skip connections\n",
        "  for up, skip in zip(up_stack, skips):\n",
        "    x = up(x)\n",
        "    x = concat([x, skip])\n",
        "\n",
        "  x = last(x)\n",
        "\n",
        "  return tf.keras.Model(inputs=inputs, outputs=x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYTE37lny8Gv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model1 = architecture1()\n",
        "model1.compile(loss='mean_squared_error', optimizer='adam')\n",
        "model1.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MQHbX1FdH0K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# what does the untrained model predict\n",
        "test_patch_nbr = 10\n",
        "X_test = sim_fw_patches[np.newaxis, test_patch_nbr,:,:,:, np.newaxis]\n",
        "print(X_test.shape)\n",
        "\n",
        "y_pred = model1.predict(X_test)\n",
        "\n",
        "print(y_pred.shape)\n",
        "\n",
        "view_slices_3d(X_test[0, :, :, :, 0], slice_nbr=16, vmin=-1, vmax=1, title='Input Tissue Phase')\n",
        "view_slices_3d(sim_gt_patches[test_patch_nbr, :, :, :], slice_nbr=16, vmin=-1, vmax=1, title='GT Susceptibility')\n",
        "view_slices_3d(y_pred[0, :, :, :, 0], slice_nbr=16, vmin=-1, vmax=1, title='Predicted Susceptibility')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UknKfZ2qZ4AP",
        "colab_type": "text"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eezZIRey_177",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jnuMt7142ZSA",
        "colab": {}
      },
      "source": [
        "# train\n",
        "checkpoint_path1 = \"checkpoints1/cp-{epoch:04d}.ckpt\"\n",
        "checkpoint_dir1 = os.path.dirname(checkpoint_path1)\n",
        "\n",
        "# Create checkpoint callback\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path1,\n",
        "                                                 save_weights_only=True,\n",
        "                                                 period=save_period,\n",
        "                                                 verbose=1)\n",
        "\n",
        "train_images=tf.expand_dims(sim_fw_patches, 4)\n",
        "train_labels=tf.expand_dims(sim_gt_patches, 4)\n",
        "\n",
        "\n",
        "history1 = model1.fit(train_images, train_labels,  epochs=epochs_train, batch_size=30, shuffle=True,\n",
        "          callbacks = [cp_callback])  # pass callback to training for saving the model\n",
        "\n",
        "loss_history1 = history1.history['loss']\n",
        "\n",
        "with open('loss_history1.pickle', 'wb') as f:\n",
        "    pickle.dump([loss_history1, epochs_train], f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RxH2n6kaF97",
        "colab_type": "text"
      },
      "source": [
        "## Load and Plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-WGdAP1kMLT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load stored data\n",
        "checkpoint_path1 = \"checkpoints1/cp-{epoch:04d}.ckpt\"\n",
        "checkpoint_dir1 = os.path.dirname(checkpoint_path1)\n",
        "model1 = architecture1()\n",
        "model1.compile(loss='mean_squared_error', optimizer='adam')\n",
        "latest1 = tf.train.latest_checkpoint(checkpoint_dir1)\n",
        "print(latest1)\n",
        "model1.load_weights(latest1)\n",
        "\n",
        "with open('loss_history1.pickle', 'rb') as f:\n",
        "    [loss_history1, epochs_train1] = pickle.load(f)\n",
        "\n",
        "# Visualize training\n",
        "def get_figure():\n",
        "    \"\"\"\n",
        "    Returns figure and axis objects to plot on. \n",
        "    Removes top and right border and ticks, because those are ugly\n",
        "    \"\"\"\n",
        "    fig, ax = plt.subplots(1)\n",
        "    plt.tick_params(top=False, right=False, which='both') \n",
        "    ax.spines['top'].set_visible(False)\n",
        "    ax.spines['right'].set_visible(False)\n",
        "    return fig, ax\n",
        "  \n",
        "fig, ax = get_figure()\n",
        "\n",
        "ax.plot(np.arange(epochs_train1) + 1, loss_history1, marker=\"o\", linewidth=2, color=\"orange\", label=\"loss1\")\n",
        "ax.set_xlabel('epoch')\n",
        "ax.legend(frameon=False);\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGVh0emV1Y7w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# did we manage to learn the training data?\n",
        "test_patch_nbr = 4\n",
        "X_test = sim_fw_patches[np.newaxis, test_patch_nbr,:,:,:, np.newaxis]\n",
        "print(X_test.shape)\n",
        "\n",
        "y_pred = model1.predict(X_test)\n",
        "\n",
        "print(y_pred.shape)\n",
        "\n",
        "view_slices_3d(X_test[0, :, :, :, 0], slice_nbr=16, vmin=-1, vmax=1, title='Input Tissue Phase')\n",
        "view_slices_3d(sim_gt_patches[test_patch_nbr, :, :, :], slice_nbr=16, vmin=-1, vmax=1, title='GT Susceptibility')\n",
        "view_slices_3d(y_pred[0, :, :, :, 0], slice_nbr=16, vmin=-1, vmax=1, title='Predicted Susceptibility')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUD2DXmN22-k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# and predicting on the full data?\n",
        "X_test = sim_fw_full[np.newaxis, :, :, :, np.newaxis]\n",
        "print(X_test.shape)\n",
        "\n",
        "y_pred = model1.predict(X_test)\n",
        "\n",
        "print(y_pred.shape)\n",
        "\n",
        "view_slices_3d(X_test[0, :, :, :, 0], slice_nbr=16, vmin=-1, vmax=1, title='Input Tissue Phase')\n",
        "view_slices_3d(sim_gt_full[:, :, :], slice_nbr=16, vmin=-1, vmax=1, title='GT Susceptibility')\n",
        "view_slices_3d(y_pred[0, :, :, :, 0], slice_nbr=16, vmin=-1, vmax=1, title='Predicted Susceptibility')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dOA-vEgRsLz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# and predicting on the brain data?\n",
        "X_test = brain_fw_full[np.newaxis, :, :, :, np.newaxis] * 10\n",
        "print(X_test.shape)\n",
        "\n",
        "y_pred = model1.predict(X_test)\n",
        "\n",
        "print(y_pred.shape)\n",
        "\n",
        "view_slices_3d(X_test[0, :, :, :, 0], slice_nbr=100, vmin=-1, vmax=1, title='Input Tissue Phase')\n",
        "view_slices_3d(brain_gt_full[:, :, :]*10, slice_nbr=100, vmin=-1, vmax=1, title='GT Susceptibility')\n",
        "view_slices_3d(y_pred[0, :, :, :, 0], slice_nbr=100, vmin=-1, vmax=1, title='Predicted Susceptibility')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HzX0tYbaTkgm"
      },
      "source": [
        "# Train Model 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRB6ina8bp-e",
        "colab_type": "text"
      },
      "source": [
        "## Prepare"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DCmHX71zTkgm",
        "colab": {}
      },
      "source": [
        "def architecture2(filter_base=64, kernel_size=3):\n",
        "  down_stack = [\n",
        "    downsample(filter_base, kernel_size, apply_batchnorm=False), # (bs, 32xxx 64 if filter base = 64)\n",
        "    downsample(filter_base*2, kernel_size), # (bs, 16xxx, 128)\n",
        "    downsample(filter_base*3, kernel_size), # (bs, 8xxx, 256)\n",
        "    downsample(filter_base*4, kernel_size), # (bs, 4xxx, 512)\n",
        "    downsample(filter_base*5, kernel_size), # (bs, 2xxx, 512)\n",
        "  ]\n",
        "\n",
        "  up_stack = [\n",
        "    upsample(filter_base*5, kernel_size, apply_dropout=True), # (bs, 16, 16, 1024)\n",
        "    upsample(filter_base*4, kernel_size, apply_dropout=True), # (bs, 32, 32, 512)\n",
        "    upsample(filter_base*3, kernel_size), # (bs, 64, 64, 256)\n",
        "    upsample(filter_base*2, kernel_size), # (bs, 128, 128, 128)\n",
        "  ]\n",
        "\n",
        "  initializer = tf.random_normal_initializer(0., 0.02)\n",
        "  last = tf.keras.layers.Conv3DTranspose(OUTPUT_CHANNELS, kernel_size,\n",
        "                                         strides=2,\n",
        "                                         padding='same',\n",
        "                                         kernel_initializer=initializer,\n",
        "                                         activation='tanh')\n",
        "\n",
        "  concat = tf.keras.layers.Concatenate()\n",
        "\n",
        "  inputs = tf.keras.layers.Input(shape=[None,None,None,1])\n",
        "  x = inputs\n",
        "\n",
        "  # Downsampling through the model\n",
        "  skips = []\n",
        "  for down in down_stack:\n",
        "    x = down(x)\n",
        "    skips.append(x)\n",
        "\n",
        "  skips = reversed(skips[:-1])\n",
        "\n",
        "  # Upsampling and establishing the skip connections\n",
        "  for up, skip in zip(up_stack, skips):\n",
        "    x = up(x)\n",
        "    x = concat([x, skip])\n",
        "\n",
        "  x = last(x)\n",
        "\n",
        "  return tf.keras.Model(inputs=inputs, outputs=x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zIf34p6pTkgo",
        "colab": {}
      },
      "source": [
        "model2 = architecture2()\n",
        "model2.compile(loss='mean_squared_error', optimizer='adam')\n",
        "model2.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4uY6yC3bwvo",
        "colab_type": "text"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ehxuFsr3Tkgu",
        "colab": {}
      },
      "source": [
        "# train\n",
        "checkpoint_path2 = \"checkpoints2/cp-{epoch:04d}.ckpt\"\n",
        "checkpoint_dir2 = os.path.dirname(checkpoint_path2)\n",
        "\n",
        "# Create checkpoint callback\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path2,\n",
        "                                                 save_weights_only=True,\n",
        "                                                 period=save_period,\n",
        "                                                 verbose=1)\n",
        "\n",
        "train_images=tf.expand_dims(sim_fw_patches, 4)\n",
        "train_labels=tf.expand_dims(sim_gt_patches, 4)\n",
        "\n",
        "\n",
        "history2 = model2.fit(train_images, train_labels,  epochs=epochs_train, batch_size=30, shuffle=True,\n",
        "          callbacks = [cp_callback])  # pass callback to training for saving the model\n",
        "\n",
        "loss_history2 = history2.history['loss']\n",
        "\n",
        "import pickle\n",
        "with open('loss_history2.pickle', 'wb') as f:\n",
        "    pickle.dump([loss_history2, epochs_train], f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evce_JMGb0uw",
        "colab_type": "text"
      },
      "source": [
        "## Load and Plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DXUoIKynTkgx",
        "colab": {}
      },
      "source": [
        "# load stored data\n",
        "checkpoint_path2 = \"checkpoints2/cp-{epoch:04d}.ckpt\"\n",
        "checkpoint_dir2 = os.path.dirname(checkpoint_path2)\n",
        "model2 = architecture2()\n",
        "model2.compile(loss='mean_squared_error', optimizer='adam')\n",
        "latest2 = tf.train.latest_checkpoint(checkpoint_dir2)\n",
        "print(latest2)\n",
        "model2.load_weights(latest2)\n",
        "\n",
        "with open('loss_history2.pickle', 'rb') as f:\n",
        "    [loss_history2, epochs_train2] = pickle.load(f)\n",
        "\n",
        "# Visualize training\n",
        "def get_figure():\n",
        "    \"\"\"\n",
        "    Returns figure and axis objects to plot on. \n",
        "    Removes top and right border and ticks, because those are ugly\n",
        "    \"\"\"\n",
        "    fig, ax = plt.subplots(1)\n",
        "    plt.tick_params(top=False, right=False, which='both') \n",
        "    ax.spines['top'].set_visible(False)\n",
        "    ax.spines['right'].set_visible(False)\n",
        "    return fig, ax\n",
        "  \n",
        "fig, ax = get_figure()\n",
        "\n",
        "ax.plot(np.arange(epochs_train2) + 1, loss_history2, marker=\"o\", linewidth=2, color=\"orange\", label=\"loss2\")\n",
        "ax.set_xlabel('epoch')\n",
        "ax.legend(frameon=False);\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cQhb8N5oTkg0",
        "colab": {}
      },
      "source": [
        "# did we manage to learn the training data?\n",
        "test_patch_nbr = 4\n",
        "X_test = sim_fw_patches[np.newaxis, test_patch_nbr,:,:,:, np.newaxis]\n",
        "print(X_test.shape)\n",
        "\n",
        "y_pred = model2.predict(X_test)\n",
        "\n",
        "print(y_pred.shape)\n",
        "\n",
        "view_slices_3d(X_test[0, :, :, :, 0], slice_nbr=16, vmin=-1, vmax=1, title='Input Tissue Phase')\n",
        "view_slices_3d(sim_gt_patches[test_patch_nbr, :, :, :], slice_nbr=16, vmin=-1, vmax=1, title='GT Susceptibility')\n",
        "view_slices_3d(y_pred[0, :, :, :, 0], slice_nbr=16, vmin=-1, vmax=1, title='Predicted Susceptibility')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8C7cfefpTkg3",
        "colab": {}
      },
      "source": [
        "# and predicting on the full data?\n",
        "X_test = sim_fw_full[np.newaxis, :, :, :, np.newaxis]\n",
        "print(X_test.shape)\n",
        "\n",
        "y_pred = model2.predict(X_test)\n",
        "\n",
        "print(y_pred.shape)\n",
        "\n",
        "view_slices_3d(X_test[0, :, :, :, 0], slice_nbr=16, vmin=-1, vmax=1, title='Input Tissue Phase')\n",
        "view_slices_3d(sim_gt_full[:, :, :], slice_nbr=16, vmin=-1, vmax=1, title='GT Susceptibility')\n",
        "view_slices_3d(y_pred[0, :, :, :, 0], slice_nbr=16, vmin=-1, vmax=1, title='Predicted Susceptibility')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YVgQYHQITkg6",
        "colab": {}
      },
      "source": [
        "# and predicting on the brain data?\n",
        "X_test = brain_fw_full[np.newaxis, :, :, :, np.newaxis] * 10\n",
        "print(X_test.shape)\n",
        "\n",
        "y_pred = model2.predict(X_test)\n",
        "\n",
        "print(y_pred.shape)\n",
        "\n",
        "view_slices_3d(X_test[0, :, :, :, 0], slice_nbr=100, vmin=-1, vmax=1, title='Input Tissue Phase')\n",
        "view_slices_3d(brain_gt_full[:, :, :]*10, slice_nbr=100, vmin=-1, vmax=1, title='GT Susceptibility')\n",
        "view_slices_3d(y_pred[0, :, :, :, 0], slice_nbr=100, vmin=-1, vmax=1, title='Predicted Susceptibility')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGuNtBuzUYb4",
        "colab_type": "text"
      },
      "source": [
        "# Compare Model 1 and 2\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXD8kiDoUjLl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('loss_history1.pickle', 'rb') as f:\n",
        "    [loss_history1, epochs_train1] = pickle.load(f)\n",
        "\n",
        "with open('loss_history2.pickle', 'rb') as f:\n",
        "    [loss_history2, epochs_train2] = pickle.load(f)\n",
        "\n",
        "# Visualize training\n",
        "def get_figure():\n",
        "    \"\"\"\n",
        "    Returns figure and axis objects to plot on. \n",
        "    Removes top and right border and ticks, because those are ugly\n",
        "    \"\"\"\n",
        "    fig, ax = plt.subplots(1)\n",
        "    plt.tick_params(top=False, right=False, which='both') \n",
        "    ax.spines['top'].set_visible(False)\n",
        "    ax.spines['right'].set_visible(False)\n",
        "    return fig, ax\n",
        "  \n",
        "fig, ax = get_figure()\n",
        "\n",
        "ax.plot(np.arange(epochs_train1) + 1, loss_history1, marker=\"o\", linewidth=2, color=\"orange\", label=\"loss1\")\n",
        "ax.plot(np.arange(epochs_train2) + 1, loss_history2, marker=\"o\", linewidth=2, color=\"blue\", label=\"loss2\")\n",
        "ax.set_xlabel('epoch')\n",
        "ax.legend(frameon=False);\n",
        "plt.ylim((0, 0.2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADNCjgrO_88Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}